{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, Word2Vec, MinHashLSH, HashingTF, IDF\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from operator import itemgetter\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo spark e carregando a base\n",
    "A base utilizada é a mesma especificada no trabalho  \n",
    "mas foi carregada direto do sklearn que já tem a base como exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines spark and load dataset!\n",
    "conf = SparkConf()\n",
    "spark = SparkSession.builder.config(conf=conf).appName('bd2-ṕi3').getOrCreate()\n",
    "proc_data = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza do dataset\n",
    "O dataset possui muita sujeira nas string  \n",
    "então é feito uma limpeza para melhor coleta  \n",
    "das features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                data|              target|\n",
      "+--------------------+--------------------+\n",
      "|I am sure some ba...|    rec.sport.hockey|\n",
      "|My brother is in ...|comp.sys.ibm.pc.h...|\n",
      "|Finally you said ...|talk.politics.mid...|\n",
      "|Think!It's the SC...|comp.sys.ibm.pc.h...|\n",
      "|1) I have an old ...|comp.sys.mac.hard...|\n",
      "|Back in high scho...|     sci.electronics|\n",
      "|AE is in Dallas.....|comp.sys.mac.hard...|\n",
      "|[stuff deleted]Ok...|    rec.sport.hockey|\n",
      "|Yeah, it's the se...|    rec.sport.hockey|\n",
      "|If a Christian me...|  talk.religion.misc|\n",
      "|the blood of the ...|  talk.religion.misc|\n",
      "|>say they have a ...|           sci.crypt|\n",
      "|930418Do what tho...|  talk.religion.misc|\n",
      "|How about Kirlian...|             sci.med|\n",
      "|There is no notio...|         alt.atheism|\n",
      "|In the following ...|talk.politics.mid...|\n",
      "|Many thanks to th...|     sci.electronics|\n",
      "|.........I, some ...|     sci.electronics|\n",
      "|The Supreme Court...|           sci.crypt|\n",
      "|ed>1. All of us t...|     rec.motorcycles|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clean dataset\n",
    "dataset = list(zip(proc_data.data,proc_data.target.tolist()))\n",
    "for i in range(len(dataset)):\n",
    "    dataset[i] = (' '.join(dataset[i][0].replace('\\n','').replace('\\t','').split()).strip(),proc_data.target_names[dataset[i][1]])  #Clean the horrible text!\n",
    "dataset = spark.createDataFrame(dataset,['data','target'])\n",
    "dataset = dataset.where(functions.col(\"data\").isNotNull())\n",
    "dataset = dataset.where(functions.col(\"target\").isNotNull())\n",
    "dataset = dataset.fillna({'data':''})\n",
    "dataset.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coleta de Features\n",
    "A partir do dataset utilizamos as ferramentas do pyspark  \n",
    "para coletar features que serão utilizadas pelo modelo  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from dataset\n",
    "tokenizer = Tokenizer(inputCol=\"data\", outputCol=\"words\")\n",
    "\n",
    "stop_words = StopWordsRemover(inputCol='words', outputCol='clean_words')\n",
    "\n",
    "word_count = CountVectorizer(inputCol='words', outputCol='features', vocabSize=1000)\n",
    "\n",
    "idf = IDF(inputCol='features',outputCol='new_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipline\n",
    "É utilizado para acelerar o processamento das features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                data|              target|               words|         clean_words|            features|        new_features|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|I am sure some ba...|    rec.sport.hockey|[i, am, sure, som...|[sure, bashers, p...|(1000,[0,1,2,3,4,...|(1000,[0,1,2,3,4,...|\n",
      "|My brother is in ...|comp.sys.ibm.pc.h...|[my, brother, is,...|[brother, market,...|(1000,[0,3,5,6,8,...|(1000,[0,3,5,6,8,...|\n",
      "|Finally you said ...|talk.politics.mid...|[finally, you, sa...|[finally, said, d...|(1000,[0,1,2,3,4,...|(1000,[0,1,2,3,4,...|\n",
      "|Think!It's the SC...|comp.sys.ibm.pc.h...|[think!it's, the,...|[think!it's, scsi...|(1000,[0,1,2,3,4,...|(1000,[0,1,2,3,4,...|\n",
      "|1) I have an old ...|comp.sys.mac.hard...|[1), i, have, an,...|[1), old, jasmine...|(1000,[0,1,3,5,6,...|(1000,[0,1,3,5,6,...|\n",
      "|Back in high scho...|     sci.electronics|[back, in, high, ...|[back, high, scho...|(1000,[0,2,3,4,5,...|(1000,[0,2,3,4,5,...|\n",
      "|AE is in Dallas.....|comp.sys.mac.hard...|[ae, is, in, dall...|[ae, dallas...try...|(1000,[2,5,6,11,1...|(1000,[2,5,6,11,1...|\n",
      "|[stuff deleted]Ok...|    rec.sport.hockey|[[stuff, deleted]...|[[stuff, deleted]...|(1000,[0,1,3,4,5,...|(1000,[0,1,3,4,5,...|\n",
      "|Yeah, it's the se...|    rec.sport.hockey|[yeah,, it's, the...|[yeah,, second, o...|(1000,[0,3,4,7,8,...|(1000,[0,3,4,7,8,...|\n",
      "|If a Christian me...|  talk.religion.misc|[if, a, christian...|[christian, means...|(1000,[0,1,2,3,5,...|(1000,[0,1,2,3,5,...|\n",
      "|the blood of the ...|  talk.religion.misc|[the, blood, of, ...|[blood, lamb.this...|(1000,[0,1,2,3,10...|(1000,[0,1,2,3,10...|\n",
      "|>say they have a ...|           sci.crypt|[>say, they, have...|[>say, \"history, ...|(1000,[2,3,14,24]...|(1000,[2,3,14,24]...|\n",
      "|930418Do what tho...|  talk.religion.misc|[930418do, what, ...|[930418do, thou, ...|(1000,[0,1,2,3,4,...|(1000,[0,1,2,3,4,...|\n",
      "|How about Kirlian...|             sci.med|[how, about, kirl...|[kirlian, imaging...|(1000,[0,1,3,4,7,...|(1000,[0,1,3,4,7,...|\n",
      "|There is no notio...|         alt.atheism|[there, is, no, n...|[notion, heliocen...|(1000,[2,6,20,39,...|(1000,[2,6,20,39,...|\n",
      "|In the following ...|talk.politics.mid...|[in, the, followi...|[following, repor...|(1000,[0,1,2,3,4,...|(1000,[0,1,2,3,4,...|\n",
      "|Many thanks to th...|     sci.electronics|[many, thanks, to...|[many, thanks, re...|(1000,[0,1,3,4,5,...|(1000,[0,1,3,4,5,...|\n",
      "|.........I, some ...|     sci.electronics|[.........i,, som...|[.........i,, yea...|(1000,[0,2,3,4,5,...|(1000,[0,2,3,4,5,...|\n",
      "|The Supreme Court...|           sci.crypt|[the, supreme, co...|[supreme, court, ...|(1000,[0,1,2,3,4,...|(1000,[0,1,2,3,4,...|\n",
      "|ed>1. All of us t...|     rec.motorcycles|[ed>1., all, of, ...|[ed>1., us, argue...|(1000,[0,1,2,3,4,...|(1000,[0,1,2,3,4,...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=[tokenizer,stop_words,word_count,idf])\n",
    "pipe = pipeline.fit(dataset)\n",
    "dataset = pipe.transform(dataset)\n",
    "dataset.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MinHash\n",
    "Utilização do MinHash para reduzir o uso  \n",
    "de memória na hora do treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh = MinHashLSH(inputCol='features', outputCol='hashes', numHashTables=10)\n",
    "model = mh.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba1f3a53d9b452f99cd7f95df8f0eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18846), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "collect_features = dataset.select('features').collect()\n",
    "predict_list = [] # Array with the preditcion from model.\n",
    "\n",
    "for i in tqdm_notebook(range(dataset.count())):\n",
    "    try: #Some values of the features are all 0 and breakes the KNN (sorry no time to fix this)\n",
    "        df_predict = model.approxNearestNeighbors(dataset, collect_features[i][0], 10) #utiliza o modelo do MinHash para treino\n",
    "        select_target = df_predict.select('target').take(1)\n",
    "        predict_list.append(select_target)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
