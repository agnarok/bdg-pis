{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF, MinHashLSH\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql import functions as f\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Scikit-Learn já tem o parser da coleção ``20 NewsGroups`` que já está separado 60% em treino e 40% em teste. Portanto, foi-se usado esse dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_data = fetch_20newsgroups(subset='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_groups = list(zip(proc_data.data, proc_data.target.tolist()))\n",
    "raw_groups = [[tupla[0],tupla[1]] for tupla in raw_groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_groups[:] = [[x[0].replace('\\n', '').replace('\\t', '').replace(';', '').replace('\\r',' '), x[1]] for x in raw_groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(raw_groups)):\n",
    "    raw_groups[i][1] = proc_data.target_names[raw_groups[i][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(raw_groups)):\n",
    "    raw_groups[i][0] = raw_groups[i][0].replace('\\n',' ')\n",
    "    raw_groups[i][0] = raw_groups[i][0].replace('\\t',' ')\n",
    "    raw_groups[i][0] = raw_groups[i][0].replace('\\r',' ')\n",
    "    raw_groups[i][0] = raw_groups[i][0].replace(';','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvar treino em um .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(raw_groups[:int(len(raw_groups) * 0.85)], columns=['data','target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I am sure some bashers of Pens fans are pret...</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>My brother is in the market for a high-perform...</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Finally you said what you dream about. Me...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Think!  It's the SCSI card doing the DMA tran...</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1)    I have an old Jasmine drive which I cann...</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16014</td>\n",
       "      <td>A Unix tool of cryptographic significance is a...</td>\n",
       "      <td>sci.crypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16015</td>\n",
       "      <td>^^^^^^^^^^^^^^^^^^^^^^^^    ...</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16016</td>\n",
       "      <td>If the Anne Frank exhibit makes it to your ...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16017</td>\n",
       "      <td>Hi I'm having a problem with TrueType fonts in...</td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16018</td>\n",
       "      <td>o Sony Color Watchman, model FDL-310   - VHF/U...</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16019 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    data  \\\n",
       "0        I am sure some bashers of Pens fans are pret...   \n",
       "1      My brother is in the market for a high-perform...   \n",
       "2           Finally you said what you dream about. Me...   \n",
       "3       Think!  It's the SCSI card doing the DMA tran...   \n",
       "4      1)    I have an old Jasmine drive which I cann...   \n",
       "...                                                  ...   \n",
       "16014  A Unix tool of cryptographic significance is a...   \n",
       "16015                    ^^^^^^^^^^^^^^^^^^^^^^^^    ...   \n",
       "16016     If the Anne Frank exhibit makes it to your ...   \n",
       "16017  Hi I'm having a problem with TrueType fonts in...   \n",
       "16018  o Sony Color Watchman, model FDL-310   - VHF/U...   \n",
       "\n",
       "                         target  \n",
       "0              rec.sport.hockey  \n",
       "1      comp.sys.ibm.pc.hardware  \n",
       "2         talk.politics.mideast  \n",
       "3      comp.sys.ibm.pc.hardware  \n",
       "4         comp.sys.mac.hardware  \n",
       "...                         ...  \n",
       "16014                 sci.crypt  \n",
       "16015          rec.sport.hockey  \n",
       "16016               alt.atheism  \n",
       "16017   comp.os.ms-windows.misc  \n",
       "16018              misc.forsale  \n",
       "\n",
       "[16019 rows x 2 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('newsgroups_train.csv', index=True, sep=';', index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvar teste em um .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(raw_groups[int(len(raw_groups) * 0.85) + 1:], columns=['data','target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('newsgroups_test.csv', index=True, sep=';', index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregar o .csv em dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Trabalho III').config('spark.some.config.option','some-value').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sem Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = spark.read.load('newsgroups_train.csv', format='csv', sep=';', header=True)\n",
    "data_train = data_train.fillna({'data':''})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = spark.read.load('newsgroups_test.csv', format='csv', sep=';', header=True)\n",
    "data_test = data_test.where(f.col(\"data\").isNotNull())\n",
    "data_test = data_test.fillna({'data':''})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+\n",
      "| id|                data|              target|\n",
      "+---+--------------------+--------------------+\n",
      "|  0|  I am sure some ...|    rec.sport.hockey|\n",
      "|  1|My brother is in ...|comp.sys.ibm.pc.h...|\n",
      "|  2|\"     Finally you...|talk.politics.mid...|\n",
      "|  3| Think!  It's the...|comp.sys.ibm.pc.h...|\n",
      "|  4|1)    I have an o...|comp.sys.mac.hard...|\n",
      "|  5|  Back in high sc...|     sci.electronics|\n",
      "|  6|  AE is in Dallas...|comp.sys.mac.hard...|\n",
      "|  7| [stuff deleted] ...|    rec.sport.hockey|\n",
      "|  8|   Yeah, it's the...|    rec.sport.hockey|\n",
      "|  9|\" If a Christian ...|  talk.religion.misc|\n",
      "| 10|the blood of the ...|  talk.religion.misc|\n",
      "| 11|\" >say they have ...|           sci.crypt|\n",
      "| 12|\"930418  Do what ...|  talk.religion.misc|\n",
      "| 13|\" How about Kirli...|             sci.med|\n",
      "| 14|   There is no no...|         alt.atheism|\n",
      "| 15|\"In the following...|talk.politics.mid...|\n",
      "| 16|\"Many thanks to t...|     sci.electronics|\n",
      "| 17|......... I, some...|     sci.electronics|\n",
      "| 18|\" The Supreme Cou...|           sci.crypt|\n",
      "| 19|\" ed>1.  All of u...|     rec.motorcycles|\n",
      "+---+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treino\n",
    "tokenizer_train = Tokenizer(inputCol='data', outputCol='tokens')\n",
    "#data_train_no_stopwords = tokenizer.transform(data_train)\n",
    "\n",
    "# teste\n",
    "tokenizer_test = Tokenizer(inputCol='data', outputCol='tokens')\n",
    "#data_test_no_stopwords = tokenizer.transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+\n",
      "| id|                data|              target|              tokens|\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "|  0|From: v064mb9k@ub...|           rec.autos|[from:, v064mb9k@...|\n",
      "|  1|\"From: Rick Mille...|      comp.windows.x|[\"from:, rick, mi...|\n",
      "|  2|From: mathew <mat...|         alt.atheism|[from:, mathew, <...|\n",
      "|  3|\"From: bakken@cs....|talk.politics.mid...|[\"from:, bakken@c...|\n",
      "|  4|\"From: livesey@so...|  talk.religion.misc|[\"from:, livesey@...|\n",
      "|  5|\"From: banschbach...|             sci.med|[\"from:, banschba...|\n",
      "|  6|From: PETCH@gvg47...|soc.religion.chri...|[from:, petch@gvg...|\n",
      "|  7|\"From: fortmann@s...|soc.religion.chri...|[\"from:, fortmann...|\n",
      "|  8|From: kartik@hls....|      comp.windows.x|[from:, kartik@hl...|\n",
      "|  9|From: tmc@spartan...|       comp.graphics|[from:, tmc@spart...|\n",
      "| 10|From: Greg.Reinac...|comp.os.ms-window...|[from:, greg.rein...|\n",
      "| 11|From: sirosh@cs.u...|      comp.windows.x|[from:, sirosh@cs...|\n",
      "| 12|\"From: tclock@ori...|talk.politics.mid...|[\"from:, tclock@o...|\n",
      "| 13|From: ray@unisql....|     rec.motorcycles|[from:, ray@unisq...|\n",
      "| 14|\"From: acooper@ma...|         alt.atheism|[\"from:, acooper@...|\n",
      "| 15|\"From: charlea@en...|comp.os.ms-window...|[\"from:, charlea@...|\n",
      "| 16|\"From: jacobs@cer...|comp.sys.mac.hard...|[\"from:, jacobs@c...|\n",
      "| 17|From: vicente@cen...|       comp.graphics|[from:, vicente@c...|\n",
      "| 18|\"From: Mike Diack...|        misc.forsale|[\"from:, mike, di...|\n",
      "| 19|From: dlb5404@tam...|  talk.politics.guns|[from:, dlb5404@t...|\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_test_no_stopwords.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treino\n",
    "cv_train = CountVectorizer(inputCol='tokens',outputCol='rawFeatures', vocabSize=130110)\n",
    "#cvmodel = cv.fit(data_train_no_stopwords)\n",
    "#data_train_no_stopwords = cvmodel.transform(data_train_no_stopwords)\n",
    "\n",
    "# teste\n",
    "cv_test = CountVectorizer(inputCol='tokens',outputCol='rawFeatures', vocabSize=130110)\n",
    "#cvmodel = cv.fit(data_test_no_stopwords)\n",
    "#data_test_no_stopwords = cvmodel.transform(data_test_no_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| id|                data|              target|              tokens|         rawFeatures|            features|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  0|From: v064mb9k@ub...|           rec.autos|[from:, v064mb9k@...|(130110,[0,1,2,3,...|(130110,[0,1,2,3,...|\n",
      "|  1|\"From: Rick Mille...|      comp.windows.x|[\"from:, rick, mi...|(130110,[0,1,2,3,...|(130110,[0,1,2,3,...|\n",
      "|  2|From: mathew <mat...|         alt.atheism|[from:, mathew, <...|(130110,[0,1,2,3,...|(130110,[0,1,2,3,...|\n",
      "|  3|\"From: bakken@cs....|talk.politics.mid...|[\"from:, bakken@c...|(130110,[0,1,2,3,...|(130110,[0,1,2,3,...|\n",
      "|  4|\"From: livesey@so...|  talk.religion.misc|[\"from:, livesey@...|(130110,[0,2,3,6,...|(130110,[0,2,3,6,...|\n",
      "|  5|\"From: banschbach...|             sci.med|[\"from:, banschba...|(130110,[0,1,2,3,...|(130110,[0,1,2,3,...|\n",
      "|  6|From: PETCH@gvg47...|soc.religion.chri...|[from:, petch@gvg...|(130110,[0,12,25,...|(130110,[0,12,25,...|\n",
      "|  7|\"From: fortmann@s...|soc.religion.chri...|[\"from:, fortmann...|(130110,[0,1,2,3,...|(130110,[0,1,2,3,...|\n",
      "|  8|From: kartik@hls....|      comp.windows.x|[from:, kartik@hl...|(130110,[0,1,4,5,...|(130110,[0,1,4,5,...|\n",
      "|  9|From: tmc@spartan...|       comp.graphics|[from:, tmc@spart...|(130110,[0,1,2,3,...|(130110,[0,1,2,3,...|\n",
      "| 10|From: Greg.Reinac...|comp.os.ms-window...|[from:, greg.rein...|(130110,[0,1,2,3,...|(130110,[0,1,2,3,...|\n",
      "| 11|From: sirosh@cs.u...|      comp.windows.x|[from:, sirosh@cs...|(130110,[0,1,2,3,...|(130110,[0,1,2,3,...|\n",
      "| 12|\"From: tclock@ori...|talk.politics.mid...|[\"from:, tclock@o...|(130110,[0,1,2,3,...|(130110,[0,1,2,3,...|\n",
      "| 13|From: ray@unisql....|     rec.motorcycles|[from:, ray@unisq...|(130110,[0,1,2,3,...|(130110,[0,1,2,3,...|\n",
      "| 14|\"From: acooper@ma...|         alt.atheism|[\"from:, acooper@...|(130110,[0,1,2,3,...|(130110,[0,1,2,3,...|\n",
      "| 15|\"From: charlea@en...|comp.os.ms-window...|[\"from:, charlea@...|(130110,[0,1,2,3,...|(130110,[0,1,2,3,...|\n",
      "| 16|\"From: jacobs@cer...|comp.sys.mac.hard...|[\"from:, jacobs@c...|(130110,[0,1,2,3,...|(130110,[0,1,2,3,...|\n",
      "| 17|From: vicente@cen...|       comp.graphics|[from:, vicente@c...|(130110,[0,6,27,2...|(130110,[0,6,27,2...|\n",
      "| 18|\"From: Mike Diack...|        misc.forsale|[\"from:, mike, di...|(130110,[0,1,3,4,...|(130110,[0,1,3,4,...|\n",
      "| 19|From: dlb5404@tam...|  talk.politics.guns|[from:, dlb5404@t...|(130110,[0,4,5,7,...|(130110,[0,4,5,7,...|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_test_no_stopwords.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treino\n",
    "idf_train = IDF(inputCol='rawFeatures',outputCol='features')\n",
    "#idfModel = idf.fit(data_train_no_stopwords)\n",
    "#data_train_no_stopwords = idfModel.transform(data_train_no_stopwords)\n",
    "\n",
    "# teste\n",
    "idf_test = IDF(inputCol='rawFeatures',outputCol='features')\n",
    "#idfModel = idf.fit(data_test_no_stopwords)\n",
    "#data_test_no_stopwords = idfModel.transform(data_test_no_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinHashLSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_train = Pipeline(stages=[tokenizer_train, cv_train, idf_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = pipeline_train.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pipeline_model.transform(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, data: string, target: string, tokens: array<string>, rawFeatures: vector, features: vector]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_test = Pipeline(stages=[tokenizer_test, cv_test, idf_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = pipeline_test.fit(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pipeline_model.transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| id|                data|              target|              tokens|         rawFeatures|            features|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  0|\"I am using the G...|      comp.windows.x|[\"i, am, using, t...|(69649,[0,1,2,3,4...|(69649,[0,1,2,3,4...|\n",
      "|  1|   There's docume...|      comp.windows.x|[, , , there's, d...|(69649,[0,1,2,3,4...|(69649,[0,1,2,3,4...|\n",
      "|  2|\"The only reason ...|soc.religion.chri...|[\"the, only, reas...|(69649,[0,1,2,3,4...|(69649,[0,1,2,3,4...|\n",
      "|  3|\" Steve,      It'...|  talk.politics.guns|[\", steve,, , , ,...|(69649,[0,1,2,3,4...|(69649,[0,1,2,3,4...|\n",
      "|  4|\"I have some bran...|        misc.forsale|[\"i, have, some, ...|(69649,[0,1,2,3,4...|(69649,[0,1,2,3,4...|\n",
      "|  5|  I wonder how ha...|comp.sys.mac.hard...|[, , i, wonder, h...|(69649,[0,1,2,3,4...|(69649,[0,1,2,3,4...|\n",
      "|  6|Derian Hatcher's ...|    rec.sport.hockey|[derian, hatcher'...|(69649,[0,1,2,3,4...|(69649,[0,1,2,3,4...|\n",
      "|  7|\"From: Center for...|talk.politics.mid...|[\"from:, center, ...|(69649,[0,1,2,3,4...|(69649,[0,1,2,3,4...|\n",
      "|  8|What are people's...|     sci.electronics|[what, are, peopl...|(69649,[0,1,2,3,4...|(69649,[0,1,2,3,4...|\n",
      "|  9|It should be note...|           sci.space|[it, should, be, ...|(69649,[0,1,2,3,4...|(69649,[0,1,2,3,4...|\n",
      "| 10| >  > The reason ...|           sci.crypt|[, >, , >, the, r...|(69649,[0,1,2,4,6...|(69649,[0,1,2,4,6...|\n",
      "| 11| You can configur...|comp.sys.ibm.pc.h...|[, you, can, conf...|(69649,[0,1,2,4,5...|(69649,[0,1,2,4,5...|\n",
      "| 12| Many Companies p...|comp.sys.mac.hard...|[, many, companie...|(69649,[0,1,4,10,...|(69649,[0,1,4,10,...|\n",
      "| 13|\" (Whatever the a...|  talk.politics.guns|[\", (whatever, th...|(69649,[0,1,2,3,4...|(69649,[0,1,2,3,4...|\n",
      "| 14|  Not to start *a...|     rec.motorcycles|[, , not, to, sta...|(69649,[0,1,2,3,4...|(69649,[0,1,2,3,4...|\n",
      "| 15|\"# # Unfortunatel...|  talk.politics.misc|[\"#, #, unfortuna...|(69649,[0,1,2,3,4...|(69649,[0,1,2,3,4...|\n",
      "| 16|\"   This has to b...|           sci.crypt|[\", , , this, has...|(69649,[0,1,2,4,5...|(69649,[0,1,2,4,5...|\n",
      "| 17|1990 Mazda MX-6  ...|        misc.forsale|[1990, mazda, mx-...|(69649,[0,553,948...|(69649,[0,553,948...|\n",
      "| 18|Count me interest...|  rec.sport.baseball|[count, me, inter...|(69649,[0,4,6,21,...|(69649,[0,4,6,21,...|\n",
      "| 19| Don't you Americ...|    rec.sport.hockey|[, don't, you, am...|(69649,[0,1,3,4,6...|(69649,[0,1,3,4,6...|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# somente necessário para o treino\n",
    "mh_train = MinHashLSH(inputCol='features', outputCol='hashes', numHashTables=10)\n",
    "model = mh_train.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/2826 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 1/2826 [00:01<1:09:01,  1.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 2/2826 [00:02<1:09:40,  1.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 3/2826 [00:04<1:14:19,  1.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 4/2826 [00:06<1:12:01,  1.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 5/2826 [00:07<1:12:12,  1.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 6/2826 [00:09<1:19:00,  1.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 7/2826 [00:12<1:31:45,  1.95s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 8/2826 [00:14<1:40:37,  2.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 9/2826 [00:17<1:42:51,  2.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 10/2826 [00:19<1:42:42,  2.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 11/2826 [00:22<1:50:39,  2.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 12/2826 [00:24<1:48:41,  2.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 13/2826 [00:26<1:46:39,  2.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 14/2826 [00:29<1:50:19,  2.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 15/2826 [00:31<1:53:56,  2.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 16/2826 [00:34<1:58:25,  2.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 17/2826 [00:36<1:55:05,  2.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 18/2826 [00:38<1:49:33,  2.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 19/2826 [00:41<1:51:51,  2.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 20/2826 [00:43<1:50:33,  2.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 21/2826 [00:46<1:51:44,  2.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 22/2826 [00:48<1:53:35,  2.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 23/2826 [00:51<1:56:08,  2.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 24/2826 [00:53<1:57:40,  2.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 25/2826 [00:56<2:04:37,  2.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 26/2826 [01:00<2:17:58,  2.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "collect_features = df_test.select('features').collect()\n",
    "predict_list = []\n",
    "\n",
    "for i in tqdm(range(df_test.count())):\n",
    "    #model.approxNearestNeighbors(data_train_no_stopwords, collect_features[i][0], 5).cache()\n",
    "    df_predict = model.approxNearestNeighbors(df_train, collect_features[i][0], 5)\n",
    "    select_target = df_predict.select('target').take(1)\n",
    "    predict_list.append(select_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
